{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6670626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/2bd0c619-af65-4059-bb97-0110ea804e3b/mubuntum/pytorchenv/pytorchenv/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/mnt/2bd0c619-af65-4059-bb97-0110ea804e3b/mubuntum/pytorchenv/pytorchenv/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import clip\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe89a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('/home/mayowa/Documents/IU/indiana_reports.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b695db",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.read_csv('/home/mayowa/Documents/IU/indiana_projections.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ffde375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No displaced rib fractures, pneumothorax, or p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No acute cardiopulmonary abnormality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No acute cardiopulmonary findings.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          impression\n",
       "0                               Normal chest x-XXXX.\n",
       "1                       No acute pulmonary findings.\n",
       "2  No displaced rib fractures, pneumothorax, or p...\n",
       "3  1. Bullous emphysema and interstitial fibrosis...\n",
       "4              No acute cardiopulmonary abnormality.\n",
       "5                 No acute cardiopulmonary findings."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.loc[:5,[\"impression\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017224c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column impression has missing values: True\n"
     ]
    }
   ],
   "source": [
    "# Check if column 'impression\"' has missing values\n",
    "has_missing_values = main_df[\"impression\"].isna().any()\n",
    "print(f\"Column impression has missing values: {has_missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b748d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(main_df[\"impression\"].isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf8dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = main_df.dropna(subset=[\"impression\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b42a6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column impression has missing values: False\n"
     ]
    }
   ],
   "source": [
    "has_missing_values = clean_df[\"impression\"].isna().any()\n",
    "print(f\"Column impression has missing values: {has_missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29018ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(clean_df[\"impression\"].isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ed601e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/mayowa/Documents/cleaned_reports.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d59e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb233acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(main_df[\"uid\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276f8886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/2bd0c619-af65-4059-bb97-0110ea804e3b/mubuntum/pytorchenv/pytorchenv/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/mnt/2bd0c619-af65-4059-bb97-0110ea804e3b/mubuntum/pytorchenv/pytorchenv/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import clip\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "\n",
    "\n",
    "class ImageTitleDataset(Dataset):\n",
    "    def __init__(self, image_csv_path, text_csv_path):\n",
    "        # Load CSV files\n",
    "        self.image_df = pd.read_csv(image_csv_path)\n",
    "        self.text_df = pd.read_csv(text_csv_path)\n",
    "        \n",
    "        # both CSVs have a \"uid\" column for linking\n",
    "        self.image_path = self.image_df['filename'].tolist()\n",
    "        self.uid = self.image_df['uid'].tolist()\n",
    "        \n",
    "        # Initialize an empty list to store text data\n",
    "        self.text_data = []\n",
    "\n",
    "        # Match \"uid\" values and load \"impression\" column from text CSV\n",
    "        for uid in self.uid:\n",
    "            text_row = self.text_df.loc[self.text_df['uid'] == uid]\n",
    "            if not text_row.empty:\n",
    "                self.text_data.append(text_row.iloc[0]['image'])\n",
    "            else:\n",
    "                # Handle cases where there is no matching \"uid\"\n",
    "                self.text_data.append(\"\")  # or any other suitable placeholder\n",
    "        # Tokenize text\n",
    "        self.title = clip.tokenize(self.text_data)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image = preprocess(Image.open(f\"/home/Documents/IU/images/images_normalized/{self.image_path[idx]}\"))\n",
    "#         #print(image)\n",
    "#         #title = clip.tokenize(self.title[idx])\n",
    "#         #print(title)\n",
    "#         return image, self.title\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = preprocess(Image.open(f\"/home/mayowa/Documents/IU/images/images_normalized/{self.image_path[idx]}\"))\n",
    "        title = self.title[idx]\n",
    "        return image, title\n",
    "\n",
    "# Example usage:\n",
    "# image_csv_path = 'image_data.csv'\n",
    "# text_csv_path = 'text_data.csv'\n",
    "# dataset = ImageTitleDataset(image_csv_path, text_csv_path)\n",
    "# image, title = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eddf1d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: \n",
    "image_csv_path = '/home/mayowa/Documents/IU/indiana_projections.csv'\n",
    "text_csv_path = '/home/mayowa/Documents/IU/indiana_reports.csv'\n",
    "dataset = ImageTitleDataset(image_csv_path, text_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657b7244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49406,    87,  3077, 10563,  2217,   537, 26646, 49407,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0], dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff3583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1645, -1.1645, -1.1645,  ..., -1.6171, -1.6171, -1.6025],\n",
       "         [-1.1645, -1.1791, -1.1791,  ..., -1.6171, -1.6171, -1.6025],\n",
       "         [-1.1791, -1.1791, -1.1791,  ..., -1.6171, -1.6171, -1.6025],\n",
       "         ...,\n",
       "         [-1.1499, -1.1499, -1.1499,  ..., -1.4857, -1.4273, -1.4419],\n",
       "         [-1.1499, -1.1207, -1.1353,  ..., -1.4565, -1.3981, -1.4127],\n",
       "         [-1.1207, -1.1061, -1.1207,  ..., -1.4565, -1.4127, -1.3835]],\n",
       "\n",
       "        [[-1.1068, -1.1068, -1.1068,  ..., -1.5720, -1.5720, -1.5570],\n",
       "         [-1.1068, -1.1218, -1.1218,  ..., -1.5720, -1.5720, -1.5570],\n",
       "         [-1.1218, -1.1218, -1.1218,  ..., -1.5720, -1.5720, -1.5570],\n",
       "         ...,\n",
       "         [-1.0918, -1.0918, -1.0918,  ..., -1.4369, -1.3769, -1.3919],\n",
       "         [-1.0918, -1.0617, -1.0767,  ..., -1.4069, -1.3469, -1.3619],\n",
       "         [-1.0617, -1.0467, -1.0617,  ..., -1.4069, -1.3619, -1.3319]],\n",
       "\n",
       "        [[-0.8688, -0.8688, -0.8688,  ..., -1.3096, -1.3096, -1.2954],\n",
       "         [-0.8688, -0.8830, -0.8830,  ..., -1.3096, -1.3096, -1.2954],\n",
       "         [-0.8830, -0.8830, -0.8830,  ..., -1.3096, -1.3096, -1.2954],\n",
       "         ...,\n",
       "         [-0.8545, -0.8545, -0.8545,  ..., -1.1816, -1.1247, -1.1389],\n",
       "         [-0.8545, -0.8261, -0.8403,  ..., -1.1532, -1.0963, -1.1105],\n",
       "         [-0.8261, -0.8119, -0.8261,  ..., -1.1532, -1.1105, -1.0821]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b8fadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7466"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c2a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your own data\n",
    "#list_image_path = ['folder/image1.jpg','folder2/image2.jpg'] \n",
    "#list_txt = ['description for image1.jpg' , 'description for image2.jpg']\n",
    "#dataset = image_title_dataset(list_image_path,list_txt)\n",
    "BATCH_SIZE = 8\n",
    "train_dataloader = DataLoader(dataset,batch_size = BATCH_SIZE, shuffle=True) #Define your own dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84abd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagei, texti = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d19f267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.7485, -1.7485, -1.7631,  ..., -1.6755, -1.4419, -1.3835],\n",
       "           [-1.7631, -1.7631, -1.7631,  ..., -1.6609, -1.4419, -1.3835],\n",
       "           [-1.7631, -1.7631, -1.7631,  ..., -1.6609, -1.4419, -1.3835],\n",
       "           ...,\n",
       "           [-1.4857, -1.4711, -1.4711,  ..., -1.3105, -1.0331, -1.0769],\n",
       "           [-1.2667, -1.2375, -1.2375,  ..., -1.0623, -0.8142, -0.9893],\n",
       "           [-1.4127, -1.3981, -1.3835,  ..., -1.1207, -0.9748, -1.1791]],\n",
       " \n",
       "          [[-1.7071, -1.7071, -1.7221,  ..., -1.6320, -1.3919, -1.3319],\n",
       "           [-1.7221, -1.7221, -1.7221,  ..., -1.6170, -1.3919, -1.3319],\n",
       "           [-1.7221, -1.7221, -1.7221,  ..., -1.6170, -1.3919, -1.3319],\n",
       "           ...,\n",
       "           [-1.4369, -1.4219, -1.4219,  ..., -1.2568, -0.9717, -1.0167],\n",
       "           [-1.2118, -1.1818, -1.1818,  ..., -1.0017, -0.7466, -0.9267],\n",
       "           [-1.3619, -1.3469, -1.3319,  ..., -1.0617, -0.9117, -1.1218]],\n",
       " \n",
       "          [[-1.4376, -1.4376, -1.4518,  ..., -1.3665, -1.1389, -1.0821],\n",
       "           [-1.4518, -1.4518, -1.4518,  ..., -1.3522, -1.1389, -1.0821],\n",
       "           [-1.4518, -1.4518, -1.4518,  ..., -1.3522, -1.1389, -1.0821],\n",
       "           ...,\n",
       "           [-1.1816, -1.1674, -1.1674,  ..., -1.0110, -0.7408, -0.7834],\n",
       "           [-0.9683, -0.9399, -0.9399,  ..., -0.7692, -0.5275, -0.6981],\n",
       "           [-1.1105, -1.0963, -1.0821,  ..., -0.8261, -0.6839, -0.8830]]],\n",
       " \n",
       " \n",
       "         [[[-1.6171, -1.6317, -1.6463,  ..., -1.7485, -1.7485, -1.7485],\n",
       "           [-1.6901, -1.6901, -1.6901,  ..., -1.7485, -1.7485, -1.7485],\n",
       "           [-1.7485, -1.7485, -1.7485,  ..., -1.7485, -1.7485, -1.7485],\n",
       "           ...,\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -0.4784, -0.6098, -0.7850],\n",
       "           [-1.7485, -1.7485, -1.7485,  ..., -0.0988, -0.2448, -0.4492],\n",
       "           [-1.7485, -1.7485, -1.7485,  ..., -0.9602, -1.0185, -1.1207]],\n",
       " \n",
       "          [[-1.5720, -1.5870, -1.6020,  ..., -1.7071, -1.7071, -1.7071],\n",
       "           [-1.6470, -1.6470, -1.6470,  ..., -1.7071, -1.7071, -1.7071],\n",
       "           [-1.7071, -1.7071, -1.7071,  ..., -1.7071, -1.7071, -1.7071],\n",
       "           ...,\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -0.4014, -0.5365, -0.7166],\n",
       "           [-1.7071, -1.7071, -1.7071,  ..., -0.0112, -0.1613, -0.3714],\n",
       "           [-1.7071, -1.7071, -1.7071,  ..., -0.8967, -0.9567, -1.0617]],\n",
       " \n",
       "          [[-1.3096, -1.3238, -1.3380,  ..., -1.4376, -1.4376, -1.4376],\n",
       "           [-1.3807, -1.3807, -1.3807,  ..., -1.4376, -1.4376, -1.4376],\n",
       "           [-1.4376, -1.4376, -1.4376,  ..., -1.4376, -1.4376, -1.4376],\n",
       "           ...,\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -0.2004, -0.3284, -0.4990],\n",
       "           [-1.4376, -1.4376, -1.4376,  ...,  0.1693,  0.0271, -0.1720],\n",
       "           [-1.4376, -1.4376, -1.4376,  ..., -0.6697, -0.7266, -0.8261]]],\n",
       " \n",
       " \n",
       "         [[[-1.4419, -1.4419, -1.4419,  ..., -1.5879, -1.5733, -1.5733],\n",
       "           [-1.4419, -1.4419, -1.4419,  ..., -1.5879, -1.5733, -1.5733],\n",
       "           [-1.4419, -1.4419, -1.4419,  ..., -1.5879, -1.5733, -1.5733],\n",
       "           ...,\n",
       "           [-1.7193, -1.7193, -1.7047,  ..., -1.5587, -1.5587, -1.5441],\n",
       "           [-1.7193, -1.7339, -1.7047,  ..., -1.5587, -1.5587, -1.5441],\n",
       "           [-1.7193, -1.7339, -1.6901,  ..., -1.5587, -1.5587, -1.5441]],\n",
       " \n",
       "          [[-1.3919, -1.3919, -1.3919,  ..., -1.5420, -1.5270, -1.5270],\n",
       "           [-1.3919, -1.3919, -1.3919,  ..., -1.5420, -1.5270, -1.5270],\n",
       "           [-1.3919, -1.3919, -1.3919,  ..., -1.5420, -1.5270, -1.5270],\n",
       "           ...,\n",
       "           [-1.6771, -1.6771, -1.6621,  ..., -1.5120, -1.5120, -1.4970],\n",
       "           [-1.6771, -1.6921, -1.6621,  ..., -1.5120, -1.5120, -1.4970],\n",
       "           [-1.6771, -1.6921, -1.6470,  ..., -1.5120, -1.5120, -1.4970]],\n",
       " \n",
       "          [[-1.1389, -1.1389, -1.1389,  ..., -1.2811, -1.2669, -1.2669],\n",
       "           [-1.1389, -1.1389, -1.1389,  ..., -1.2811, -1.2669, -1.2669],\n",
       "           [-1.1389, -1.1389, -1.1389,  ..., -1.2811, -1.2669, -1.2669],\n",
       "           ...,\n",
       "           [-1.4091, -1.4091, -1.3949,  ..., -1.2527, -1.2527, -1.2385],\n",
       "           [-1.4091, -1.4233, -1.3949,  ..., -1.2527, -1.2527, -1.2385],\n",
       "           [-1.4091, -1.4233, -1.3807,  ..., -1.2527, -1.2527, -1.2385]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.6171, -1.6171, -1.6171,  ..., -1.7631, -1.7923, -1.7923],\n",
       "           [-1.6755, -1.6755, -1.6755,  ..., -1.7777, -1.7923, -1.7923],\n",
       "           [-1.7047, -1.7047, -1.7047,  ..., -1.7777, -1.7923, -1.7923],\n",
       "           ...,\n",
       "           [-0.8580, -0.7120, -0.1864,  ...,  1.0252,  1.0690,  1.1566],\n",
       "           [-0.4200, -0.2010,  0.3683,  ...,  1.7844,  1.7990,  1.8135],\n",
       "           [ 0.2077,  0.4851,  1.0690,  ...,  1.9303,  1.9303,  1.9303]],\n",
       " \n",
       "          [[-1.5720, -1.5720, -1.5720,  ..., -1.7221, -1.7521, -1.7521],\n",
       "           [-1.6320, -1.6320, -1.6320,  ..., -1.7371, -1.7521, -1.7521],\n",
       "           [-1.6621, -1.6621, -1.6621,  ..., -1.7371, -1.7521, -1.7521],\n",
       "           ...,\n",
       "           [-0.7916, -0.6415, -0.1012,  ...,  1.1444,  1.1894,  1.2795],\n",
       "           [-0.3414, -0.1163,  0.4691,  ...,  1.9248,  1.9398,  1.9548],\n",
       "           [ 0.3040,  0.5891,  1.1894,  ...,  2.0749,  2.0749,  2.0749]],\n",
       " \n",
       "          [[-1.3096, -1.3096, -1.3096,  ..., -1.4518, -1.4802, -1.4802],\n",
       "           [-1.3665, -1.3665, -1.3665,  ..., -1.4660, -1.4802, -1.4802],\n",
       "           [-1.3949, -1.3949, -1.3949,  ..., -1.4660, -1.4802, -1.4802],\n",
       "           ...,\n",
       "           [-0.5701, -0.4279,  0.0840,  ...,  1.2643,  1.3069,  1.3922],\n",
       "           [-0.1435,  0.0698,  0.6244,  ...,  2.0037,  2.0179,  2.0321],\n",
       "           [ 0.4679,  0.7381,  1.3069,  ...,  2.1459,  2.1459,  2.1459]]],\n",
       " \n",
       " \n",
       "         [[[ 0.7187,  0.6457,  0.6019,  ..., -1.0769, -1.0915, -1.1061],\n",
       "           [ 0.6895,  0.6165,  0.5873,  ..., -1.0915, -1.0769, -1.0915],\n",
       "           [ 0.6457,  0.5873,  0.5435,  ..., -1.0769, -1.0769, -1.1061],\n",
       "           ...,\n",
       "           [-0.9456, -0.9164, -0.9310,  ..., -1.2083, -1.1937, -1.1791],\n",
       "           [-0.9456, -0.9310, -0.9310,  ..., -1.1937, -1.2083, -1.1937],\n",
       "           [-0.9748, -0.9310, -0.9456,  ..., -1.2083, -1.1937, -1.1791]],\n",
       " \n",
       "          [[ 0.8292,  0.7542,  0.7092,  ..., -1.0167, -1.0317, -1.0467],\n",
       "           [ 0.7992,  0.7242,  0.6942,  ..., -1.0317, -1.0167, -1.0317],\n",
       "           [ 0.7542,  0.6942,  0.6491,  ..., -1.0167, -1.0167, -1.0467],\n",
       "           ...,\n",
       "           [-0.8816, -0.8516, -0.8666,  ..., -1.1518, -1.1368, -1.1218],\n",
       "           [-0.8816, -0.8666, -0.8666,  ..., -1.1368, -1.1518, -1.1368],\n",
       "           [-0.9117, -0.8666, -0.8816,  ..., -1.1518, -1.1368, -1.1218]],\n",
       " \n",
       "          [[ 0.9656,  0.8945,  0.8519,  ..., -0.7834, -0.7977, -0.8119],\n",
       "           [ 0.9372,  0.8661,  0.8377,  ..., -0.7977, -0.7834, -0.7977],\n",
       "           [ 0.8945,  0.8377,  0.7950,  ..., -0.7834, -0.7834, -0.8119],\n",
       "           ...,\n",
       "           [-0.6555, -0.6270, -0.6412,  ..., -0.9114, -0.8972, -0.8830],\n",
       "           [-0.6555, -0.6412, -0.6412,  ..., -0.8972, -0.9114, -0.8972],\n",
       "           [-0.6839, -0.6412, -0.6555,  ..., -0.9114, -0.8972, -0.8830]]],\n",
       " \n",
       " \n",
       "         [[[-1.0185, -1.0477, -1.0477,  ..., -1.0331, -0.9456, -0.8872],\n",
       "           [-1.0623, -1.0915, -1.0915,  ..., -1.0769, -1.0039, -0.9602],\n",
       "           [-1.0915, -1.1061, -1.1207,  ..., -1.1061, -1.0477, -1.0185],\n",
       "           ...,\n",
       "           [ 0.7187,  0.2369, -0.2886,  ..., -1.1353, -1.1207, -1.1353],\n",
       "           [ 0.7187,  0.1201, -0.1280,  ..., -1.1353, -1.1207, -1.1353],\n",
       "           [ 0.5143,  0.0909, -0.0113,  ..., -1.1207, -1.0915, -1.0915]],\n",
       " \n",
       "          [[-0.9567, -0.9867, -0.9867,  ..., -0.9717, -0.8816, -0.8216],\n",
       "           [-1.0017, -1.0317, -1.0317,  ..., -1.0167, -0.9417, -0.8967],\n",
       "           [-1.0317, -1.0467, -1.0617,  ..., -1.0467, -0.9867, -0.9567],\n",
       "           ...,\n",
       "           [ 0.8292,  0.3340, -0.2063,  ..., -1.0767, -1.0617, -1.0767],\n",
       "           [ 0.8292,  0.2139, -0.0412,  ..., -1.0767, -1.0617, -1.0767],\n",
       "           [ 0.6191,  0.1839,  0.0789,  ..., -1.0617, -1.0317, -1.0317]],\n",
       " \n",
       "          [[-0.7266, -0.7550, -0.7550,  ..., -0.7408, -0.6555, -0.5986],\n",
       "           [-0.7692, -0.7977, -0.7977,  ..., -0.7834, -0.7123, -0.6697],\n",
       "           [-0.7977, -0.8119, -0.8261,  ..., -0.8119, -0.7550, -0.7266],\n",
       "           ...,\n",
       "           [ 0.9656,  0.4964, -0.0156,  ..., -0.8403, -0.8261, -0.8403],\n",
       "           [ 0.9656,  0.3826,  0.1409,  ..., -0.8403, -0.8261, -0.8403],\n",
       "           [ 0.7666,  0.3542,  0.2546,  ..., -0.8261, -0.7977, -0.7977]]]]),\n",
       " tensor([[49406,  2217,   537, 26646, 10563,   343,   268, 22819, 13564, 22819,\n",
       "            267, 22819,   536, 22819,   335,   269,   332,   852, 49407,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [49406, 10563,   273,   341, 35794,   270, 26646, 22819,   267, 22819,\n",
       "          22819, 22819, 49407,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [49406, 10563,   273,   341, 35794,   270, 26646, 49407,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [49406,  2217,   537, 26646, 10563,  7176,  4407,   525, 22819,   536,\n",
       "            271,   273,   281,   274,   274,  2382,   269, 49407,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [49406,    87,  3077, 10563,  2217,   537, 26646, 49407,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [49406,    87,  3077, 10563,  2217,   537, 26646, 49407,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [49406, 10563,   273,   341, 35794,   270, 26646, 22819,   267, 22819,\n",
       "          22819,   990, 49407,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [49406,    87,  3077, 10563,  2217,   537, 26646, 49407,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagei, texti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d13b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1\n",
    "\n",
    "#https://github.com/openai/CLIP/issues/57\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        p.grad.data = p.grad.data.float() \n",
    "\n",
    "\n",
    "if device == \"cpu\":\n",
    "  model.float()\n",
    "else :\n",
    "  clip.model.convert_weights(model) # Actually this line is unnecessary since clip by default already on float16\n",
    "\n",
    "loss_img = nn.CrossEntropyLoss()\n",
    "loss_txt = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) #Params used from paper, the lr is smaller, more safe for fine tuning to new dataset\n",
    "\n",
    "# add your own code to track the training progress.\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "  for batch in tqdm(train_dataloader):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      images,texts = batch \n",
    "    \n",
    "      images= images.to(device)\n",
    "      texts = texts.to(device)\n",
    "    \n",
    "      logits_per_image, logits_per_text = model(images, texts)\n",
    "\n",
    "      ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
    "\n",
    "      total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "      total_loss.backward()\n",
    "      if device == \"cpu\":\n",
    "         optimizer.step()\n",
    "      else : \n",
    "        convert_models_to_fp32(model)\n",
    "        optimizer.step()\n",
    "        clip.model.convert_weights(model)\n",
    "    print(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e0a2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': total_loss,\n",
    "        }, f\"model_checkpoint/model_10.pt\") #just change to your preferred folder/filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb67b164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "checkpoint = torch.load(\"model_checkpoint/model_10.pt\")\n",
    "\n",
    "# Use these 3 lines if you use default model setting(not training setting) of the clip. For example, if you set context_length to 100 since your string is very long during training, then assign 100 to checkpoint['model_state_dict'][\"context_length\"] \n",
    "#checkpoint['model_state_dict'][\"input_resolution\"] = model.input_resolution #default is 224\n",
    "#checkpoint['model_state_dict'][\"context_length\"] = model.context_length # default is 77\n",
    "#checkpoint['model_state_dict'][\"vocab_size\"] = model.vocab_size \n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
